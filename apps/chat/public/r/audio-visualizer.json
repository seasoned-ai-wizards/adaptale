{
  "name": "audio-visualizer",
  "type": "registry:ui",
  "files": [
    {
      "path": "ui/audio-visualizer.tsx",
      "content": "\"use client\"\n\nimport { useEffect, useRef } from \"react\"\n\n// Configuration constants for the audio analyzer\nconst AUDIO_CONFIG = {\n  FFT_SIZE: 512,\n  SMOOTHING: 0.8,\n  MIN_BAR_HEIGHT: 2,\n  MIN_BAR_WIDTH: 2,\n  BAR_SPACING: 1,\n  COLOR: {\n    MIN_INTENSITY: 100, // Minimum gray value (darker)\n    MAX_INTENSITY: 255, // Maximum gray value (brighter)\n    INTENSITY_RANGE: 155, // MAX_INTENSITY - MIN_INTENSITY\n  },\n} as const\n\ninterface AudioVisualizerProps {\n  stream: MediaStream | null\n  isRecording: boolean\n  onClick: () => void\n}\n\nexport function AudioVisualizer({\n  stream,\n  isRecording,\n  onClick,\n}: AudioVisualizerProps) {\n  // Refs for managing audio context and animation\n  const canvasRef = useRef<HTMLCanvasElement>(null)\n  const audioContextRef = useRef<AudioContext | null>(null)\n  const analyserRef = useRef<AnalyserNode | null>(null)\n  const animationFrameRef = useRef<number>()\n  const containerRef = useRef<HTMLDivElement>(null)\n\n  // Cleanup function to stop visualization and close audio context\n  const cleanup = () => {\n    if (animationFrameRef.current) {\n      cancelAnimationFrame(animationFrameRef.current)\n    }\n    if (audioContextRef.current) {\n      audioContextRef.current.close()\n    }\n  }\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return cleanup\n  }, [])\n\n  // Start or stop visualization based on recording state\n  useEffect(() => {\n    if (stream && isRecording) {\n      startVisualization()\n    } else {\n      cleanup()\n    }\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n  }, [stream, isRecording])\n\n  // Handle window resize\n  useEffect(() => {\n    const handleResize = () => {\n      if (canvasRef.current && containerRef.current) {\n        const container = containerRef.current\n        const canvas = canvasRef.current\n        const dpr = window.devicePixelRatio || 1\n\n        // Set canvas size based on container and device pixel ratio\n        const rect = container.getBoundingClientRect()\n        // Account for the 2px total margin (1px on each side)\n        canvas.width = (rect.width - 2) * dpr\n        canvas.height = (rect.height - 2) * dpr\n\n        // Scale canvas CSS size to match container minus margins\n        canvas.style.width = `${rect.width - 2}px`\n        canvas.style.height = `${rect.height - 2}px`\n      }\n    }\n\n    window.addEventListener(\"resize\", handleResize)\n    // Initial setup\n    handleResize()\n\n    return () => window.removeEventListener(\"resize\", handleResize)\n  }, [])\n\n  // Initialize audio context and start visualization\n  const startVisualization = async () => {\n    try {\n      const audioContext = new AudioContext()\n      audioContextRef.current = audioContext\n\n      const analyser = audioContext.createAnalyser()\n      analyser.fftSize = AUDIO_CONFIG.FFT_SIZE\n      analyser.smoothingTimeConstant = AUDIO_CONFIG.SMOOTHING\n      analyserRef.current = analyser\n\n      const source = audioContext.createMediaStreamSource(stream!)\n      source.connect(analyser)\n\n      draw()\n    } catch (error) {\n      console.error(\"Error starting visualization:\", error)\n    }\n  }\n\n  // Calculate the color intensity based on bar height\n  const getBarColor = (normalizedHeight: number) => {\n    const intensity =\n      Math.floor(normalizedHeight * AUDIO_CONFIG.COLOR.INTENSITY_RANGE) +\n      AUDIO_CONFIG.COLOR.MIN_INTENSITY\n    return `rgb(${intensity}, ${intensity}, ${intensity})`\n  }\n\n  // Draw a single bar of the visualizer\n  const drawBar = (\n    ctx: CanvasRenderingContext2D,\n    x: number,\n    centerY: number,\n    width: number,\n    height: number,\n    color: string\n  ) => {\n    ctx.fillStyle = color\n    // Draw upper bar (above center)\n    ctx.fillRect(x, centerY - height, width, height)\n    // Draw lower bar (below center)\n    ctx.fillRect(x, centerY, width, height)\n  }\n\n  // Main drawing function\n  const draw = () => {\n    if (!isRecording) return\n\n    const canvas = canvasRef.current\n    const ctx = canvas?.getContext(\"2d\")\n    if (!canvas || !ctx || !analyserRef.current) return\n\n    const dpr = window.devicePixelRatio || 1\n    ctx.scale(dpr, dpr)\n\n    const analyser = analyserRef.current\n    const bufferLength = analyser.frequencyBinCount\n    const frequencyData = new Uint8Array(bufferLength)\n\n    const drawFrame = () => {\n      animationFrameRef.current = requestAnimationFrame(drawFrame)\n\n      // Get current frequency data\n      analyser.getByteFrequencyData(frequencyData)\n\n      // Clear canvas - use CSS pixels for clearing\n      ctx.clearRect(0, 0, canvas.width / dpr, canvas.height / dpr)\n\n      // Calculate dimensions in CSS pixels\n      const barWidth = Math.max(\n        AUDIO_CONFIG.MIN_BAR_WIDTH,\n        canvas.width / dpr / bufferLength - AUDIO_CONFIG.BAR_SPACING\n      )\n      const centerY = canvas.height / dpr / 2\n      let x = 0\n\n      // Draw each frequency bar\n      for (let i = 0; i < bufferLength; i++) {\n        const normalizedHeight = frequencyData[i] / 255 // Convert to 0-1 range\n        const barHeight = Math.max(\n          AUDIO_CONFIG.MIN_BAR_HEIGHT,\n          normalizedHeight * centerY\n        )\n\n        drawBar(\n          ctx,\n          x,\n          centerY,\n          barWidth,\n          barHeight,\n          getBarColor(normalizedHeight)\n        )\n\n        x += barWidth + AUDIO_CONFIG.BAR_SPACING\n      }\n    }\n\n    drawFrame()\n  }\n\n  return (\n    <div\n      ref={containerRef}\n      className=\"h-full w-full cursor-pointer rounded-lg bg-background/80 backdrop-blur\"\n      onClick={onClick}\n    >\n      <canvas ref={canvasRef} className=\"h-full w-full\" />\n    </div>\n  )\n}\n",
      "type": "registry:ui",
      "target": ""
    }
  ]
}
